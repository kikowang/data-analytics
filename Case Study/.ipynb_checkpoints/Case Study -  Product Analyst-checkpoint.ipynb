{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user related data\n",
    "user_engagements = pd.read_csv('user_engagements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transaction related data\n",
    "\n",
    "transaction_dimensions = pd.read_csv('transaction_dimensions.csv')\n",
    "transaction_financials = pd.read_csv('transaction_financials.csv')\n",
    "dim_channel = pd.read_csv('dim_channel.csv')\n",
    "currency_details = pd.read_csv('currency_details.csv')\n",
    "fx_rates_eur = pd.read_csv('fx_rates_eur.csv')\n",
    "cities = pd.read_csv('cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference data - not useful for this task, so skipped\n",
    "#platforms = pd.read_csv('platforms.csv')\n",
    "#country_currency_mapping = pd.read_csv('country_currency_mapping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Checking and cleaning user related data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagements.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_engagements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagements.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagements.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dummy variable column for transaction and login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in missing values,based on if there is no login_id or transaction_id, it means it is not logged in, or not transacted\n",
    "\n",
    "user_engagements['loginid'].fillna(0,inplace=True)\n",
    "user_engagements['transaction_id'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagements['transaction_dummy'] = user_engagements['transaction_id'].apply(dummy)\n",
    "user_engagements['login_dummy'] = user_engagements['loginid'].apply(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagements.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert string variables to numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date to weekday/weekend\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = user_engagements['sessiondatetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "user_engagements['Date'] = pd.to_datetime(user_engagements['sessiondatetime'].str[:10], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagements['Time'] = pd.to_datetime(user_engagements['sessiondatetime'].str[12:], format='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagements['day_of_week'] = user_engagements['Date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As there are too many flavors in day of week, I'll create a dummy variable for if it's weekday(0) or weekend(1)\n",
    "\n",
    "def day(x):\n",
    "    if x.weekday() <=5:\n",
    "        return \"Weekday\"\n",
    "    if x.weekday() >5:\n",
    "        return \"Weekend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagements.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagements['Day'] = user_engagements['Date'].apply(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekend(x):\n",
    "    if x == \"Weekend\":\n",
    "        return 1\n",
    "    if x == \"Weekday\":\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagements['Weekend_dummy'] = user_engagements['Day'].apply(weekend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagements.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagements.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#platform\n",
    "\n",
    "user_engagements['platform'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dummy(x, y):\n",
    "    if x == y:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagements['WEB'] = user_engagements['platform'].apply(check_dummy, args=('WEB',))\n",
    "user_engagements['APP'] = user_engagements['platform'].apply(check_dummy, args=('APP',))\n",
    "user_engagements['WEBSITE'] = user_engagements['platform'].apply(check_dummy, args=('WEBSITE',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagements.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save user related data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagements.to_csv( \"1_user_engagements.csv\", sep=',', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring variables relevant to purchase probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,5,8,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "user_engagements= pd.read_csv('1_user_engagements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_duration</th>\n",
       "      <th>login_dummy</th>\n",
       "      <th>Weekend_dummy</th>\n",
       "      <th>WEB</th>\n",
       "      <th>APP</th>\n",
       "      <th>WEBSITE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_dummy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>155.993085</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.184015</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>548.814049</td>\n",
       "      <td>0.54064</td>\n",
       "      <td>0.188154</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.769455</td>\n",
       "      <td>0.230545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   visit_duration  login_dummy  Weekend_dummy   WEB       APP  \\\n",
       "transaction_dummy                                                               \n",
       "0                      155.993085      0.00000       0.184015  0.25  0.750000   \n",
       "1                      548.814049      0.54064       0.188154  0.00  0.769455   \n",
       "\n",
       "                    WEBSITE  \n",
       "transaction_dummy            \n",
       "0                  0.000000  \n",
       "1                  0.230545  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring variables\n",
    "\n",
    "user_engagements.groupby('transaction_dummy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"platform\", hue =\"transaction_dummy\", data=user_engagements, palette=\"Blues\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"day_of_week\", hue =\"transaction_dummy\", data=user_engagements, palette=\"Blues\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Day\", hue =\"transaction_dummy\", data=user_engagements, palette=\"Blues\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on data exploration, I'd liek to included the following independent variables and dependent variables.\n",
    "\n",
    "DV:\n",
    "transaction_dummy\n",
    "\n",
    "\n",
    "IVs:\n",
    "- visit_duration\n",
    "- login_dummy\n",
    "- Weekend_dummy\n",
    "- WEB\t\n",
    "- APP\t\n",
    "- WEBSITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sessionid             642458\n",
       "funnel_level          642479\n",
       "customerid           1042477\n",
       "userid                642458\n",
       "visit_duration        642479\n",
       "loginid                    0\n",
       "platform                   0\n",
       "transaction_id             0\n",
       "sessiondatetime       642458\n",
       "transaction_dummy          0\n",
       "login_dummy                0\n",
       "Date                  642458\n",
       "Time                  642458\n",
       "Day                   642458\n",
       "Weekend_dummy         642458\n",
       "WEB                        0\n",
       "APP                        0\n",
       "WEBSITE                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_engagements.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'll drop the rows with missing values in DVs\n",
    "\n",
    "df_user = user_engagements.dropna(subset=['visit_duration','Weekend_dummy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionid</th>\n",
       "      <th>funnel_level</th>\n",
       "      <th>customerid</th>\n",
       "      <th>userid</th>\n",
       "      <th>visit_duration</th>\n",
       "      <th>loginid</th>\n",
       "      <th>platform</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>sessiondatetime</th>\n",
       "      <th>transaction_dummy</th>\n",
       "      <th>login_dummy</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Day</th>\n",
       "      <th>Weekend_dummy</th>\n",
       "      <th>WEB</th>\n",
       "      <th>APP</th>\n",
       "      <th>WEBSITE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03327977b7c2fba25bb131922983a882f40945b5</td>\n",
       "      <td>service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d4c7eb82ca3b613e395aaebc1559f4d007899bbc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>WEB</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-24 08:41:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-24</td>\n",
       "      <td>1900-01-01 08:41:00</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0b56a45b8dbd6cb5323a3a7b80be3eb48ea3f7ba</td>\n",
       "      <td>service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a07394c246f775799ca71492fcfd6ef6dce4a084</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>APP</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-10 07:53:06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-10</td>\n",
       "      <td>1900-01-01 07:53:06</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1d8de5efe1ac81ea2fa193dff9546d3af5af5764</td>\n",
       "      <td>service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4e13f53409a9887e936107dd3a016d9cfbc5a067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>APP</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-26 18:08:22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>1900-01-01 08:08:22</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c9fff1caf5cef6054e76136e5f523974332baea5</td>\n",
       "      <td>service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f3ad470495b9cd4623edd79a151ad834c8b21c75</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>APP</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-23 19:55:24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>1900-01-01 09:55:24</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d7bdc47e1b3ad58e9f80a87c5d5f3a3a2c7cebac</td>\n",
       "      <td>service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84fa728e41e8b6edd935f275d35772ad294face1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>APP</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-29 12:44:49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>1900-01-01 02:44:49</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sessionid funnel_level customerid  \\\n",
       "0  03327977b7c2fba25bb131922983a882f40945b5      service        NaN   \n",
       "1  0b56a45b8dbd6cb5323a3a7b80be3eb48ea3f7ba      service        NaN   \n",
       "2  1d8de5efe1ac81ea2fa193dff9546d3af5af5764      service        NaN   \n",
       "3  c9fff1caf5cef6054e76136e5f523974332baea5      service        NaN   \n",
       "4  d7bdc47e1b3ad58e9f80a87c5d5f3a3a2c7cebac      service        NaN   \n",
       "\n",
       "                                     userid  visit_duration loginid platform  \\\n",
       "0  d4c7eb82ca3b613e395aaebc1559f4d007899bbc             0.0       0      WEB   \n",
       "1  a07394c246f775799ca71492fcfd6ef6dce4a084            45.0       0      APP   \n",
       "2  4e13f53409a9887e936107dd3a016d9cfbc5a067             1.0       0      APP   \n",
       "3  f3ad470495b9cd4623edd79a151ad834c8b21c75          1199.0       0      APP   \n",
       "4  84fa728e41e8b6edd935f275d35772ad294face1             3.0       0      APP   \n",
       "\n",
       "  transaction_id      sessiondatetime  transaction_dummy  login_dummy  \\\n",
       "0              0  2020-05-24 08:41:00                  0            0   \n",
       "1              0  2020-05-10 07:53:06                  0            0   \n",
       "2              0  2019-12-26 18:08:22                  0            0   \n",
       "3              0  2019-12-23 19:55:24                  0            0   \n",
       "4              0  2019-12-29 12:44:49                  0            0   \n",
       "\n",
       "         Date                 Time      Day  Weekend_dummy  WEB  APP  WEBSITE  \n",
       "0  2020-05-24  1900-01-01 08:41:00  Weekend            1.0    1    0        0  \n",
       "1  2020-05-10  1900-01-01 07:53:06  Weekend            1.0    0    1        0  \n",
       "2  2019-12-26  1900-01-01 08:08:22  Weekday            0.0    0    1        0  \n",
       "3  2019-12-23  1900-01-01 09:55:24  Weekday            0.0    0    1        0  \n",
       "4  2019-12-29  1900-01-01 02:44:49  Weekend            1.0    0    1        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = df_user[['transaction_dummy','visit_duration','Weekend_dummy','login_dummy','WEB','APP','WEBSITE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_dummy    0\n",
       "visit_duration       0\n",
       "Weekend_dummy        0\n",
       "login_dummy          0\n",
       "WEB                  0\n",
       "APP                  0\n",
       "WEBSITE              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling for predicting purchase probabbility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running Logit Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(user, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1156129 924903 231226\n"
     ]
    }
   ],
   "source": [
    "print(len(user), len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_clf = LogisticRegression(max_iter=1000, fit_intercept = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given there are 3 categories for 'platform', I created 2 features.\n",
    "\n",
    "features1 = ['visit_duration','Weekend_dummy','login_dummy','APP','WEBSITE']\n",
    "features2 = ['visit_duration','Weekend_dummy','login_dummy','WEB','WEBSITE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_clf.fit(train[features1], train['transaction_dummy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>visit_duration</th>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weekend_dummy</th>\n",
       "      <td>-0.249955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>login_dummy</th>\n",
       "      <td>9.302506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APP</th>\n",
       "      <td>-0.564668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEBSITE</th>\n",
       "      <td>1.063848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "visit_duration  0.000106\n",
       "Weekend_dummy  -0.249955\n",
       "login_dummy     9.302506\n",
       "APP            -0.564668\n",
       "WEBSITE         1.063848"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.transpose(logit_clf.coef_), features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first feature used 'WEB' as the default platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.520214\n",
      "         Iterations: 3\n",
      "         Function evaluations: 40\n",
      "         Gradient evaluations: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "logit1 = sm.Logit(train['transaction_dummy'], sm.add_constant(train[features1]))\n",
    "result1 = logit1.fit(method='bfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      transaction_dummy   No. Observations:               924903\n",
      "Model:                          Logit   Df Residuals:                   924897\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Mon, 14 Nov 2022   Pseudo R-squ.:                  0.1936\n",
      "Time:                        15:58:33   Log-Likelihood:            -4.8115e+05\n",
      "converged:                      False   LL-Null:                   -5.9663e+05\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -0.0162      0.007     -2.195      0.028      -0.031      -0.002\n",
      "visit_duration     0.0014   8.03e-06    178.849      0.000       0.001       0.001\n",
      "Weekend_dummy     -0.0040      0.006     -0.678      0.498      -0.015       0.007\n",
      "login_dummy        0.2289      0.006     40.128      0.000       0.218       0.240\n",
      "APP                0.0010      0.008      0.120      0.905      -0.015       0.017\n",
      "WEBSITE            0.0448      0.011      4.087      0.000       0.023       0.066\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(result1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second feature used 'APP' as the default platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1789: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.517794\n",
      "         Iterations: 3\n",
      "         Function evaluations: 40\n",
      "         Gradient evaluations: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wan14\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      transaction_dummy   No. Observations:               924903\n",
      "Model:                          Logit   Df Residuals:                   924897\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Mon, 14 Nov 2022   Pseudo R-squ.:                  0.1973\n",
      "Time:                        15:58:38   Log-Likelihood:            -4.7891e+05\n",
      "converged:                      False   LL-Null:                   -5.9663e+05\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -0.0150      0.004     -3.445      0.001      -0.024      -0.006\n",
      "visit_duration     0.0014   8.01e-06    179.097      0.000       0.001       0.001\n",
      "Weekend_dummy     -0.0037      0.006     -0.639      0.523      -0.015       0.008\n",
      "login_dummy        0.2270      0.006     39.809      0.000       0.216       0.238\n",
      "WEB               -0.0609      0.008     -7.290      0.000      -0.077      -0.045\n",
      "WEBSITE            0.0443      0.007      6.257      0.000       0.030       0.058\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logit2 = sm.Logit(train['transaction_dummy'], sm.add_constant(train[features2]))\n",
    "result2 = logit2.fit(method='bfgs')\n",
    "print(result2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "\n",
    "The 2 models are all significant (p < .001).\n",
    "- The visit duration, logged in status, platform (Web or Website) are significant indicators for the purchase probability.\n",
    "- The weekend dummy and APP platform are not significant indicators for the purchase probability.\n",
    "\n",
    "\n",
    "**1) visit duration**\n",
    "\n",
    "Holding everything else constant, with a one second increase in visit duration, we will see 0.14% times increase in the odds of making a purchase.\n",
    "\n",
    "**2) login_dummy**\n",
    "\n",
    "Holding everything else constant, if the user is logged in (vs not logged in), we will see 0.23 times increase in the odds of making a purchase.\n",
    "\n",
    "**3) platform**\n",
    "\n",
    "Holding everything else constant, if user is using the Website, we will see 0.04 times increase in the odds of making a purchase.\n",
    "\n",
    "Holding everything else constant, if user is using the WEB, we will see 0.06 times decrease in the odds of making a purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Checking and processing transaction related data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_dimensions.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_channel.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_financials.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_details.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_rates_eur.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_dimensions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_channel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_financials.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_details.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merging transaction_dimensions and dim_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_dimensions_1 = transaction_dimensions.merge(dim_channel, on='channel_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_dimensions_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merging transaction_financials and currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_financials_1 = transaction_financials.merge(currency_details, on='currency', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_financials_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge two above tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_new = transaction_dimensions_1.merge(transaction_financials_1, on='transaction_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add currency rate data and city info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.merge(transaction_new, fx_rates_eur, how='left', left_on='currency_x', right_on='ccy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['currency_x'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge(df1, cities, how='left', left_on='customercityid', right_on='city_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv( \"2_transaction_data.csv\", sep=',', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting purchase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
